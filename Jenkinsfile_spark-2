pipeline {
    agent any
    tools {
        maven 'maven'
    }

    environment{
        SPARK_HOME = "/opt/spark"
    }

    stages {
        stage('Checkout External Code'){
            steps{
                git branch: 'master',
                url: 'https://github.com/muzafferjoya/spark-hello-world.git'
            }
        }
        stage ('Initialize') {
            steps {
                sh '''
                    echo "PATH = ${PATH}"
                    echo "M2_HOME = ${M2_HOME}"
                ''' 
            }
        }
        stage('Build') {
            steps {
                 
                sh 'mvn clean package'
                
            }
        }
        stage('Deploy') {
            steps {
                
                sh '${SPARK_HOME}/bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.0 --class com.kitmenke.spark.MyStreamingApp spark-hello-world-1.0-SNAPSHOT.jar'
                
            }
        }
        
    }
     
}

---------------------------------------------------------------------------------------------------------------------------------------

pipeline {
    agent any
    tools {
        maven 'mvn'
    }
        
    stages {
        stage('Checkout External Code'){
            steps{
                git branch: 'master',
                url: 'https://github.com/muzafferjoya/spark-hello-world.git'
            }
        }
        stage ('Initialize') {
            steps {
                sh '''
                    echo "PATH = ${PATH}"
                    echo "M2_HOME = ${M2_HOME}"
                ''' 
            }
        }
        stage('Build') {
            steps {
                 
                sh 'mvn clean package'
                
            }
        }
        stage('Deploy'){
            steps{
             sh "${SPARK_HOME}/bin/spark-submit --class com.kitmenke.spark.MyStreamingApp /var/lib/jenkins/workspace/spark-wrk/target/spark-hello-world-1.0-SNAPSHOT.jar"
            }
        }
        
        
    }
     
}

-------------------------------------------------------------------------------------------------------------------------------------------

=============================================================================================================


spark-submit --class  io.github.adrianulbona.spark.HelloRDD spark-scala-maven-0.0.1-SNAPSHOT.jar


==============================================================================================================

pipeline {
    agent any
    tools{
        maven 'maven'
    }
    environment{
        SPARK_HOME = "/opt/spark"
    }
    stages {
        stage('Checkout External Code'){
            steps{
                git branch: 'master',
                url: 'https://github.com/arvindaggmca1234/spark-scala-maven.git'
            }
        }
        stage ('Initialize') {
            steps {
                sh '''
                    echo "PATH = ${PATH}"
                    echo "M2_HOME = ${M2_HOME}"
                ''' 
            }
        }
        stage('Build') {
            steps {
                 
                sh 'mvn clean package'
                
            }
        }
        stage('Deploy'){
            steps{
             sh "${SPARK_HOME}/bin/spark-submit --class  io.github.adrianulbona.spark.HelloRDD /var/lib/jenkins/workspace/spark/target/spark-scala-maven-0.0.1-SNAPSHOT.jar"
            }
        }
        
        
    }
     
}

---------------------------------------------------------------------------------------------------------------------------------------

FROM openjdk:8-alpine
RUN apk --update add wget tar bash
RUN wget https://archive.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz
RUN tar -xzf spark-3.0.3-bin-hadoop2.7.tgz && \
mv spark-2.4.8-bin-hadoop2.7 /spark && \
rm spark-2.4.8-bin-hadoop2.7.tgz
RUN export SPARK_HOME=/spark 
RUN export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
RUN export PYSPARK_PYTHON=/usr/bin/python3







FROM ubuntu 
RUN apt-get -y update
RUN apt-get -y install curl
RUN apt-get -y install software-properties-common
 
# Java
RUN echo oracle-java8-installer shared/accepted-oracle-license-v1-1 select true | debconf-set-selections && \
  add-apt-repository -y ppa:webupd8team/java && \
  apt-get update && \
  apt-get install -y oracle-java8-installer && \
  rm -rf /var/lib/apt/lists/* && \
  rm -rf /var/cache/oracle-jdk8-installer
ENV JAVA_HOME /usr/lib/jvm/java-8-oracle
 
ENV PATH $PATH:$JAVA_HOME/bin
    
# SPARK
ARG SPARK_ARCHIVE=https://archive.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz
ENV SPARK_HOME /usr/local/spark-3.0.3-bin-hadoop2.7
 
ENV PATH $PATH:${SPARK_HOME}/bin
RUN curl -s ${SPARK_ARCHIVE} | tar -xz -C /usr/local/
 
WORKDIR $SPARK_HOME







FROM ubuntu:18.04
RUN apt-get -y update
RUN apt-get -y install -y openjdk-8-jdk
ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
ENV PATH $PATH:$JAVA_HOME/bin
RUN wget https://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz
RUN tar -xvzf apache-maven-3.8.4-bin.tar.gz
RUN mv apache-maven-3.8.4 /opt/mvn
RUN wget https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz && tar xvf spark-3.2.1-bin-hadoop3.2.tgz
RUN mv spark-3.2.1-bin-hadoop3.2 /opt/spark
RUN echo "export SPARK_HOME=/opt/spark" >> ~/.profile && \
echo "export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin" >> ~/.profile && \
echo "export PYSPARK_PYTHON=/usr/bin/python3" >> ~/.profile
RUN source ~/.profile


#ENV M2_HOME=/opt/mvn
#ENV PATH $PATH:${M2_HOME}/bin:${PATH}
#RUN echo "export M2_HOME=/opt/maven" >> ~/.bashrc && echo "export PATH=${M2_HOME}/bin:${PATH}" >> ~/.bashrc




export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export PYSPARK_PYTHON=/usr/bin/python3


RUN spark-submit --class io.github.adrianulbona.spark.HelloRDD /home/spark-scala-maven-0.0.1-SNAPSHOT.jar




+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
=============================================================================================================
spark-maven-java |
-----------------

FROM ubuntu
RUN apt-get -y update
RUN apt-get install -y openjdk-8-jdk && apt-get -y install wget zip unzip vim curl
ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
ENV PATH $PATH:$JAVA_HOME/bin
RUN wget https://dlcdn.apache.org/maven/maven-3/3.8.4/binaries/apache-maven-3.8.4-bin.tar.gz
RUN tar -xvzf apache-maven-3.8.4-bin.tar.gz
RUN mv apache-maven-3.8.4 /opt/mvn
ENV M2_HOME=/opt/mvn
ENV PATH $PATH:${M2_HOME}/bin:${PATH}
RUN wget https://archive.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz
RUN tar xvf spark-3.0.3-bin-hadoop2.7.tgz
RUN mv spark-3.0.3-bin-hadoop2.7 /opt/spark
ENV SPARK_HOME=/opt/spark
ENV PATH $PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
RUN echo $JAVA_HOME && echo $M2_HOME && echo $SPARK_HOME
COPY /target/spark-scala-maven-0.0.1-SNAPSHOT.jar /home/spark-scala-maven-0.0.1-SNAPSHOT.jar
#RUN spark-submit --class io.github.adrianulbona.spark.HelloRDD /home/spark-scala-maven-0.0.1-SNAPSHOT.jar
ENTRYPOINT ["/opt/spark/bin/spark-submit"]

==============================================================================================================
How to build.?
docker build -f Dockerfile-spark -t spark-maven-java .

How to run.?
docker run spark-maven-java 

docker run spark-maven-java --class io.github.adrianulbona.spark.HelloRDD /home/spark-scala-maven-0.0.1-SNAPSHOT.jar

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++


docker pull muzaffarjoya/spark-docker:v1


